{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ast\n",
    "import math\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from simplification.cutil import simplify_coords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import ast\n",
    "import cv2\n",
    "import csv\n",
    "import time\n",
    "import ast\n",
    "import urllib\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "from dask import bag, threaded\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pltc\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import bag, threaded\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.nasnet import NASNetMobile\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import os\n",
    "\n",
    "Base_Size = 256\n",
    "data_Directory = 'C:/Users/wangy/OneDrive/Desktop/Doodle/Doodle_Data/'\n",
    "input_Directory = 'C:/Users/wangy/OneDrive/Desktop/Doodle/Prediction/'\n",
    "sub_Directory = 'D:/APM/'\n",
    "num_csv = 100\n",
    "num_class = 340\n",
    "size = 64\n",
    "steps = 1\n",
    "batchsize = 256\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "print(os.listdir(\"C:/Users/wangy/OneDrive/Desktop/Doodle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "def draw_cv2(raw_strokes, size=size, lw=6):\n",
    "    img = np.zeros((Base_Size, Base_Size))\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            img = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 255, lw)\n",
    "    return (cv2.resize(img, (size, size))/ 255.)\n",
    "\n",
    "#Data Augmentation\n",
    "def image_generator(size, batchsize, ks, lw=6):\n",
    "    while True:\n",
    "        for k in np.random.permutation(ks):\n",
    "            filename = os.path.join(data_Directory, 'train_k{}.csv.gz'.format(k))\n",
    "            for df in pd.read_csv(filename, chunksize=batchsize):\n",
    "                x = np.zeros((len(df), size, size))\n",
    "                df['drawing'] = [ast.literal_eval(pts) for pts in df['drawing'].values]   \n",
    "                df['drawing'] = df['drawing'].apply(draw_cv2)\n",
    "                x = np.vstack([a for a in df['drawing']]).reshape((len(df),size,size,1))\n",
    "                y = tf.keras.utils.to_categorical(df.y, num_classes=num_class)\n",
    "                yield x, y\n",
    "                  \n",
    "\n",
    "def df_to_image_array(df, size=size, lw=6):\n",
    "    df['drawing'] = [ast.literal_eval(pts) for pts in df['drawing'].values]\n",
    "    x = np.zeros((len(df), size, size))\n",
    "    df['drawing'] = df['drawing'].apply(draw_cv2)\n",
    "    x = np.vstack([a for a in df['drawing']]).reshape((len(df),size,size,1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(os.path.join(data_Directory, 'train_k{}.csv.gz'.format(num_csv - 1)), nrows=30000)\n",
    "x_valid = df_to_image_array(valid_df, size)\n",
    "y_valid = tf.keras.utils.to_categorical(valid_df.y, num_classes=num_class)\n",
    "print(x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image_generator(size=size, batchsize=batchsize, ks=range(num_csv - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = num_class\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(size,size,1),padding='same'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "#model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "                      metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.3, patience=5,\n",
    "                      min_delta=0.005, mode='max', verbose=1),\n",
    "    ModelCheckpoint('CNN.h5', monitor='val_top_3_accuracy', mode='max', save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "\n",
    "clf = model.fit(\n",
    "    train_datagen, steps_per_epoch=steps, epochs=epochs, verbose=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(model, title):\n",
    "    plt.plot(model.history['categorical_accuracy'])\n",
    "    plt.plot(model.history['val_categorical_accuracy'])\n",
    "    plt.plot(model.history['top_3_accuracy'])\n",
    "    plt.plot(model.history['val_top_3_accuracy'])\n",
    "    plt.title('Accuracy ' + title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation', 'Train Top 3', 'Validation Top 3'], loc='lower right')\n",
    "    plt.show()\n",
    "    plt.plot(model.history['categorical_crossentropy'])\n",
    "    plt.plot(model.history['val_categorical_crossentropy'])\n",
    "    plt.title('Loss ' + title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(clf, \"Simple CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn in for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following code is excerpt from Kaggle and changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = []\n",
    "chunksize = 10000\n",
    "reader = pd.read_csv(input_Directory + 'test_simplified.csv', chunksize=chunksize)\n",
    "for chunk in tqdm(reader):\n",
    "    imgs = df_to_image_array(chunk)\n",
    "    pred = model.predict(imgs, verbose=1)\n",
    "    top_3 =  np.argsort(-pred)[:, 0:3]  \n",
    "    pred_results.append(top_3)\n",
    "print(\"Finished test predictions...\")\n",
    "\n",
    "#prepare data for saving\n",
    "classes_path = os.listdir(sub_Directory + 'train_simplified/')\n",
    "classes_path = sorted(classes_path, key=lambda s: s.lower())\n",
    "class_dict = {x[:-4].replace(\" \", \"_\"):i for i, x in enumerate(classes_path)}\n",
    "\n",
    "reverse_dict = {v: k for k, v in class_dict.items()}\n",
    "pred_results = np.concatenate(pred_results)\n",
    "print(\"Finished data prep...\")\n",
    "\n",
    "preds_df = pd.DataFrame({'first': pred_results[:,0], 'second': pred_results[:,1], 'third': pred_results[:,2]})\n",
    "preds_df = preds_df.replace(reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df['words'] = preds_df['first'] + \" \" + preds_df['second'] + \" \" + preds_df['third']\n",
    "\n",
    "sub = pd.read_csv(input_Directory + 'sample_submission.csv', index_col=['key_id'])\n",
    "sub['word'] = preds_df.words.values\n",
    "sub.to_csv('cnn.csv')\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
